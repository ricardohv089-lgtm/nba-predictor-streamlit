import os, sys, streamlit as st, pandas as pd
import data_fetcher as df
from data_saver import collect_season_data

sys.path.append(os.path.dirname(__file__))

st.set_page_config(page_title="ğŸ€â€¯NBAâ€¯Datasetâ€¯Collector", layout="wide")
st.title("ğŸ€â€¯NBAâ€¯Dataâ€¯Collectorâ€¯&â€¯Realâ€‘Timeâ€¯Dashboardâ€¯(ESPNâ€¯Openâ€¯Feeds)")

st.markdown("""
Collectâ€¯multiâ€‘seasonâ€¯NBAâ€¯gameâ€¯dataâ€¯andâ€¯analyzeâ€¯liveâ€¯results.  
Noâ€¯APIâ€‘keysâ€¯required;â€¯dataâ€¯fetchedâ€¯directlyâ€¯fromâ€¯ESPNâ€¯publicâ€¯endpoints.
""")

# -------------------------------
# LIVE GAMES SECTION
# -------------------------------
st.subheader("ğŸŸï¸â€¯Live / Upcomingâ€¯Gamesâ€¯")
live = df.get_live_scoreboard()
st.dataframe(live if not live.empty else pd.DataFrame([{"Info": "Noâ€¯liveâ€¯gamesâ€¯rightâ€¯now"}]), use_container_width=True)

# -------------------------------
# HISTORICAL PAST WEEK SECTION
# -------------------------------
st.subheader("ğŸ“šâ€¯Pastâ€¯Weekâ€¯Finalâ€¯Scores")
week = df.get_historical_games()
st.dataframe(week if not week.empty else pd.DataFrame([{"Info": "Noâ€¯recentâ€¯finals"}]), use_container_width=True)

# -------------------------------
# DATA COLLECTION SECTION
# -------------------------------
st.subheader("ğŸ—‚ï¸â€¯Collectâ€¯andâ€¯Saveâ€¯Fullâ€¯Datasetâ€¯(3â€‘5â€¯Seasons)")
seasons_back = st.slider("Howâ€¯manyâ€¯seasonsâ€¯toâ€¯collectâ€¯?", 3, 5, 5)
if st.button("Collectâ€¯Dataset"):
    st.info(f"Collectingâ€¯pastâ€¯{seasons_back}â€¯seasonsâ€¯â€”â€¯pleaseâ€¯waitâ€¯aâ€¯fewâ€¯minutesâ€¯â³")
    dataset = collect_season_data(seasons_back)
    if not dataset.empty:
        st.success(f"Savedâ€¯{len(dataset)}â€¯gamesâ€¯fromâ€¯{seasons_back}â€¯seasonsâ€¯âœ…")
        st.dataframe(dataset.head(25))
    else:
        st.error("Failedâ€¯toâ€¯collectâ€¯dataâ€¯â€”â€¯checkâ€¯connectionâ€¯orâ€¯ESPNâ€¯availability.")

st.caption("Allâ€¯dataâ€¯importedâ€¯fromâ€¯ESPNâ€¯openâ€¯JSONâ€¯feedsâ€¯(officialâ€¯publicâ€¯source).")
